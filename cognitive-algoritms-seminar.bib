
@book{sutton_reinforcement_2020,
	address = {Cambridge, Massachusetts London, England},
	edition = {Second edition},
	series = {Adaptive computation and machine learning},
	title = {Reinforcement learning: an introduction},
	isbn = {978-0-262-03924-6},
	shorttitle = {Reinforcement learning},
	abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
	language = {en},
	publisher = {The MIT Press},
	author = {Sutton, Richard S. and Barto, Andrew},
	year = {2020},
	file = {Sutton and Barto - 2020 - Reinforcement learning an introduction.pdf:/home/pierre/Zotero/storage/JJHRMHB3/Sutton and Barto - 2020 - Reinforcement learning an introduction.pdf:application/pdf},
}

@article{peng_machine_2021,
	title = {Machine {Learning} {Techniques} for {Personalised} {Medicine} {Approaches} in {Immune}-{Mediated} {Chronic} {Inflammatory} {Diseases}: {Applications} and {Challenges}},
	volume = {12},
	shorttitle = {Machine {Learning} {Techniques} for {Personalised} {Medicine} {Approaches} in {Immune}-{Mediated} {Chronic} {Inflammatory} {Diseases}},
	doi = {10.3389/fphar.2021.720694},
	abstract = {In the past decade, the emergence of machine learning (ML) applications has led to significant advances towards implementation of personalised medicine approaches for improved health care, due to the exceptional performance of ML models when utilising complex big data. The immune-mediated chronic inflammatory diseases are a group of complex disorders associated with dysregulated immune responses resulting in inflammation affecting various organs and systems. The heterogeneous nature of these diseases poses great challenges for tailored disease management and addressing unmet patient needs. Applying novel ML techniques to the clinical study of chronic inflammatory diseases shows promising results and great potential for precision medicine applications in clinical research and practice. In this review, we highlight the clinical applications of various ML techniques for prediction, diagnosis and prognosis of autoimmune rheumatic diseases, inflammatory bowel disease, autoimmune chronic kidney disease, and multiple sclerosis, as well as ML applications for patient stratification and treatment selection. We highlight the use of ML in drug development, including target identification, validation and drug repurposing, as well as challenges related to data interpretation and validation, and ethical concerns related to the use of artificial intelligence in clinical research.},
	journal = {Frontiers in Pharmacology},
	author = {Peng, Junjie and Jury, Elizabeth and Dönnes, Pierre and Ciurtin, Coziana},
	month = sep,
	year = {2021},
	file = {Full Text:/home/pierre/Zotero/storage/PXUFTHHP/Peng et al. - 2021 - Machine Learning Techniques for Personalised Medic.pdf:application/pdf},
}

@article{fahad_mon_reinforcement_2023,
	title = {Reinforcement {Learning} in {Education}: {A} {Literature} {Review}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-9709},
	shorttitle = {Reinforcement {Learning} in {Education}},
	url = {https://www.mdpi.com/2227-9709/10/3/74},
	doi = {10.3390/informatics10030074},
	abstract = {The utilization of reinforcement learning (RL) within the field of education holds the potential to bring about a significant shift in the way students approach and engage with learning and how teachers evaluate student progress. The use of RL in education allows for personalized and adaptive learning, where the difficulty level can be adjusted based on a student’s performance. As a result, this could result in heightened levels of motivation and engagement among students. The aim of this article is to investigate the applications and techniques of RL in education and determine its potential impact on enhancing educational outcomes. It compares the various policies induced by RL with baselines and identifies four distinct RL techniques: the Markov decision process, partially observable Markov decision process, deep RL network, and Markov chain, as well as their application in education. The main focus of the article is to identify best practices for incorporating RL into educational settings to achieve effective and rewarding outcomes. To accomplish this, the article thoroughly examines the existing literature on using RL in education and its potential to advance educational technology. This work provides a thorough analysis of the various techniques and applications of RL in education to answer questions related to the effectiveness of RL in education and its future prospects. The findings of this study will provide researchers with a benchmark to compare the usefulness and effectiveness of commonly employed RL algorithms and provide direction for future research in education.},
	language = {en},
	number = {3},
	urldate = {2024-01-20},
	journal = {Informatics},
	author = {Fahad Mon, Bisni and Wasfi, Asma and Hayajneh, Mohammad and Slim, Ahmad and Abu Ali, Najah},
	month = sep,
	year = {2023},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {artificial intelligence, education, Markov decision process, reinforcement learning},
	pages = {74},
	file = {Full Text PDF:/home/pierre/Zotero/storage/T5QQJ83U/Fahad Mon et al. - 2023 - Reinforcement Learning in Education A Literature .pdf:application/pdf},
}

@inproceedings{sunwoo_comparison_2021,
	title = {Comparison of deep reinforcement learning algorithms: {Path} {Search} in {Grid} {World}},
	shorttitle = {Comparison of deep reinforcement learning algorithms},
	url = {https://ieeexplore.ieee.org/abstract/document/9369800},
	doi = {10.1109/ICEIC51217.2021.9369800},
	abstract = {Deep reinforcement learning is being used to teach robots elaborate and complex tasks, and recently, it has gained successful results in various fields of robotics. However, there is still a limit to directly applying the existing deep reinforcement learning algorithms due to the continuous and high-dimensional states and actions inherent in the robot, and a method of inducing correct learning through proper expression of the environment in which the robot will work is required. As a way to enable the robot to recognize the work environment, there is observation through a camera, and a mapping from this to the grid world is a way to express the work environment. This allows us to considerably reduce the dimensions of state and action and find the optimal policy for the path search problem using deep reinforcement learning algorithms. In this paper, we compare the simulation results of various deep reinforcement learning algorithms for path search, which is a representative problem depicted as a grid world, and present the environment, model architecture and parameters used in the simulation.},
	urldate = {2024-01-21},
	booktitle = {2021 {International} {Conference} on {Electronics}, {Information}, and {Communication} ({ICEIC})},
	author = {SunWoo, YungMin and Lee, WonChang},
	month = jan,
	year = {2021},
	pages = {1--3},
	file = {IEEE Xplore Full Text PDF:/home/pierre/Zotero/storage/BVEQZ655/SunWoo and Lee - 2021 - Comparison of deep reinforcement learning algorith.pdf:application/pdf},
}

@book{saha_practical_2023,
	title = {Practical {Autonomous} {Driving}: {A} {Survey} of {Challenges} and {Opportunities}},
	shorttitle = {Practical {Autonomous} {Driving}},
	abstract = {Autonomous Driving (AD) has become a prominent research area in the field of Artificial Intelligence (AI) and Machine Learning (ML) in recent years. This opens the door wider for self-driving cars to surpass conventional vehicles in the current market share. Despite its apparent simplicity, AD is composed of complex and heterogeneous systems, which are in need of a high level of coordination and alignment to ensure both full automation and safety. Therefore, numerous research studies have been conducted over the last few years to facilitate such coordination and accelerate the capacity of these types of vehicles to be self-managed in complex situations. The paper summarises these approaches that led to building what is known nowadays as the autonomous driving pipeline. Moreover, although skepticism exists regarding the practicality of AD as a viable alternative to traditional vehicles, extensive research suggests the multiple benefits of relying on them for mobility. While challenges remain in implementing AD in the real world, including regulation and technical issues, substantial progress in recent years indicates a growing acceptance of AD in the near future. This paper further explores the advantages and opportunities of the conducted such systems in facilitating the practicality of Autonomous Driving.},
	publisher = {Preprints},
	author = {Saha, Debanjan and De, Shuvodeep},
	month = oct,
	year = {2023},
	doi = {10.20944/preprints202202.0123.v2},
	file = {Full Text PDF:/home/pierre/Zotero/storage/L44D2B27/Saha and De - 2023 - Practical Autonomous Driving A Survey of Challeng.pdf:application/pdf},
}

@inproceedings{wiedebach_walking_2016,
	title = {Walking on {Partial} {Footholds} {Including} {Line} {Contacts} with the {Humanoid} {Robot} {Atlas}},
	url = {http://arxiv.org/abs/1607.08089},
	doi = {10.1109/HUMANOIDS.2016.7803439},
	abstract = {We present a method for humanoid robot walking on partial footholds such as small stepping stones and rocks with sharp surfaces. Our algorithm does not rely on prior knowledge of the foothold, but information about an expected foothold can be used to improve the stepping performance. After a step is taken, the robot explores the new contact surface by attempting to shift the center of pressure around the foot. The available foothold is inferred by the way in which the foot rotates about contact edges and/or by the achieved center of pressure locations on the foot during exploration. This estimated contact area is then used by a whole body momentum-based control algorithm. To walk and balance on partial footholds, we combine fast, dynamic stepping with the use of upper body angular momentum to regain balance. We applied this method to the Atlas humanoid designed by Boston Dynamics to walk over small contact surfaces, such as line and point contacts. We present experimental results and discuss performance limitations.},
	urldate = {2024-01-22},
	booktitle = {2016 {IEEE}-{RAS} 16th {International} {Conference} on {Humanoid} {Robots} ({Humanoids})},
	author = {Wiedebach, Georg and Bertrand, Sylvain and Wu, Tingfan and Fiorio, Luca and McCrory, Stephen and Griffin, Robert and Nori, Francesco and Pratt, Jerry},
	month = nov,
	year = {2016},
	note = {arXiv:1607.08089 [cs]},
	keywords = {Computer Science - Robotics},
	pages = {1312--1319},
	file = {arXiv Fulltext PDF:/home/pierre/Zotero/storage/2EEFJAMW/Wiedebach et al. - 2016 - Walking on Partial Footholds Including Line Contac.pdf:application/pdf;arXiv.org Snapshot:/home/pierre/Zotero/storage/I6KDXAIH/1607.html:text/html},
}
